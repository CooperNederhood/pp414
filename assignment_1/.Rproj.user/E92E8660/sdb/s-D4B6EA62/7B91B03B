{
    "collab_server" : "",
    "contents" : "---\noutput: \n  pdf_document:\n    keep_tex: true\n    fig_caption: true\ntitle: \"SOC30005: Homework 2\"\nauthor: \"Ma Xiangyu\"\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  echo = FALSE,\n  options(digits = 2)\n)\n```\n\n```{r, include = FALSE}\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(knitr)\nlibrary(gmodels)\nlibrary(kableExtra)\nlibrary(stargazer)\nlibrary(pander)\nlibrary(haven)\nlibrary(modelr)\n```\n\n\n# Q1.\n\n## (a)\n\n```{r}\nmean_income <- 5311\nmean_sch <- 10.2\n\nb = 0.72 * 2153/2.3\n\na <- mean_income - 0.72*mean_sch\n```\n\n$$ \\hat Y = 5300 + 674 X $$\n\n## (b)\n\n```{r}\n0.72^2\n```\n\n Variance explained  = $R^{2}$ = 0.52\n \n \n# Q2.\n\n```{r}\ngss <- read_dta(\"GSS2004.DTA\")\n```\n\n\n```{r}\n#select relevant columns=\nq2a <- select(gss, rincom98, gender1, educ) %>% drop_na(rincom98, educ) %>% filter(gender1==1)\n\n# cast column into numeric type\nq2a$incomebracket <- as.numeric(q2a$rincom98)\n\n#recode income\nq2a$income <- recode(q2a$incomebracket,\n                     `1` = 500L,\n                     `2` = 2000L,\n                     `3` = 3500L,\n                     `4` = 4500L,\n                     `5` = 5500L,\n                     `6` = 6500L, \n                     `7`= 7500L,\n                     `8`=9000L,\n                     `9`=11250L,\n                     `10` = 13750L,\n                     `11`= 16250L,\n                     `12` = 18750L,\n                     `13` = 21250L,\n                     `14` = 23750L,\n                     `15` = 27500L,\n                     `16` = 32500L,\n                     `17` = 37500L,\n                     `18` = 45000L,\n                     `19` = 55000L,\n                     `20`= 67500L,\n                     `21` = 82500L,\n                     `22` = 100000L,\n                     `23` = 150000L\n                     )\n```\n\n```{r}\n#lm model\nlmq2a <- lm(income~educ, q2a)\n\n#add predictions\npredq2a <- add_predictions(q2a, lmq2a)\n```\n\n## (a)\n\n```{r, results='asis'}\nstargazer(lmq2a, header=FALSE)\n```\n\n\n0.146 of the variation in income is explained by education. One reason could be that variance in income has risen greatly since 1960, whereas the variance in education has not changed much. The standard deviation of income in 2004 is 36399, much higher the 2153 reported in the 1960 GSS. On the other hand, the standard deviation of years of schooling in 2004 stands at `r sqrt(var(q2a$educ))`, which is only marginally greater than the 2.3 reported in the 1960 GSS.\n\n## (b)\n\nAssuming that a high school graduate has 12 years of education, someone with a BA 16 years, and the last 20 years of education:\n\n```{r}\nq2b <- tibble(educ = c(12,16,20)) %>%\n  add_predictions(lmq2a, var = \"Predicted Income\") %>%\n  rename(\"Years of Education\" = educ)\n\nkable(q2b,\n      digits = 1, \n      row.names = TRUE,\n      format = 'latex',\n      caption = \"Predicted Income, given education\",\n      booktabs = T) %>%\nkable_styling(latex_options = c(\"hold_position\"))\n```\n\n## (c)\n\n```{r}\n#recode education into a categorical variable\nq2a$educ_cat <- cut(q2a$educ, 20, labels = c(1:20))\n```\n\n\n```{r}\nanova2c <- aov(income~educ_cat, q2a)\n```\n\n```{r}\nsummary(anova2c)\n```\n\n\n```{r}\n(2.37e+11)/((1.11e+12)+(2.37e+11))\n```\n\n\n$\\eta^{2} = 0.18$\n\nThey are not the same. $\\eta^{2}$ uses variance around subgroup means whereas $r^{2}$ uses variance around the regression line.\n\n\n## (d)\n\n```{r}\nmean_educ_q2d <- group_by(q2a, educ) %>% summarise(avg =  mean(income))\n```\n\n\n```{r}\n# I introduced jitter to the scatterplot to avoid overplotting since there are a lot of overlapping points.\nggplot()+\n  geom_jitter(mapping = aes(x = educ, y = income), data = q2a, size = 1.5, alpha = 0.25)+\n  geom_smooth(method = 'lm', mapping = aes(x = educ, y = income), data= q2a, se = FALSE, size = 1.0)+\n  geom_line(data = mean_educ_q2d, mapping = aes( x = educ, y = avg), color = \"orangered\", size = 1.0)+\n  theme_light()+\n  labs(\n    x = \"Years of Education\",\n    y = \"Annual Income\",\n    title = \"Figure 1: Relationship between income and years of education\",\n    caption = \"Based on data from the 2004 GSS.\"\n  )+\n  annotate(geom = \"text\", x = 5.5, y = 50000, label = \"Line connecting means\", alpha = 0.75)+\n  annotate(geom = \"text\", x = 7.5, y = -10000, label = \"Regression line\", alpha = 0.75)\n  \n```\n\nComparing the set of means to the regression line:\n\n* The regression line deviates from the line of means most at the extreme. This suggests that when years of education is low or high, the relationship between education and annual income is no longer linear.\n\nComparing the means with the plots of the graph:\n\n* For the most part, the means occur where there's a density of points. Again, this isn't true at the extremas. The mean doesn't seem to be a good measure of central tendency when education is high, the data seems to be very dispersed, with many respondents reporting high income.\n\n# Q3.\n\n## The effect of education on health.\n\nI find myself intrigued by research on the effect of education on health (started by Grossman 1972 that continues today): in brief, it seems that education improves health, even after controlling for all sorts of confounding variables. For this part of the homework, I'd like to explore the association of education with health using data from the 2002 General Social Survey.\n\nTo begin, I operationalize the dependent variable, health, by respondents' self-reports of health conditions. Respondents are asked, \"Would you say that in general your health is Excellent, Very good, Good, Fair, or Poor?\"\n\n```{r}\ngss_2002 <- read_dta(\"GSS2002.DTA\")\n```\n\nFirst, some naive cross-tabulations of health and education.\n\n```{r}\nq3a <- select(gss_2002, health1, educ, degree, incom16, cohort, hlthinfo, race ) %>% drop_na(health1, educ)\n\n```\n\n\n```{r}\n#recode health so that 1 is low and 5 is high\nq3a$health2 <- as.numeric(q3a$health1)\nq3a$health <- recode(q3a$health2,\n                     `1` = 5L,\n                     `2` = 4L,\n                     `3` = 3L,\n                     `4` = 2L,\n                     `5` = 1L\n                     )\n```\n\n```{r}\nmytable1 <- table(q3a$educ, q3a$health)\nkable(mytable1,\n      digits = 1, \n      row.names = TRUE,\n      col.names = c(\"Poor\", \"Fair \", \"Good\", \"Very good\", \"Excellent\"),\n      format = 'latex',\n      caption = \"Cross-tabulation of health by years of education\",\n      booktabs = T) %>%\nkable_styling(latex_options = c(\"hold_position\")) %>%\nadd_header_above(c(\"Years of Education\" = 1, \"Health condition by self-report\" = 5))\n```\n\n\nOne issue with this contingency table is that there are too many few cells with very few cases. To illustrate the case with contingency tables, I'll collapse years of education into 6 categories. I tried to create categories that with samples large enough to minimize errors and which were also meaningful, to avoid doing excessive violence to the original data. To wit: \n\n* Very Low (<7)\n* Low (7-11)\n* Moderate (12)\n* High (13-15)\n* Very high (16)\n* Too much (>16)\n\nThe categories have some intuitive meaning as well: very low corresponds to those who didn't finish elementary school, low those who didn't finish middle school, moderate to high school graduates, high to those who went to college (but didn't graduate), very high to college graduates, too much to those who attended graduate school and beyond.\n\n```{r}\n# cast column into numeric type\nq3a$educ_bracket <- as.numeric(q3a$educ)\n\n# collapse educ\nq3a$educ_collapsed <- cut(q3a$educ_bracket,\n                  c(-0.5,6.5,11.5,12.5,15.5,16.5,20),\n                  labels = c(\"Very low\", \"Low\", \"Moderate\", \"High\", \"Very high\", \"Too much\"),\n                  ordered_result = TRUE)\n```\n\n\n```{r}\nmytable2 <- prop.table(table(q3a$educ_collapsed, q3a$health),1) %>% addmargins(2) *100 \nkable(mytable2,\n      digits = 1, \n      row.names = TRUE,\n      col.names = c(\"Poor (%)\", \"Fair (%)\", \"Good (%)\", \"Very good (%)\", \"Excellent (%)\", \"Total (%)\"),\n      format = 'latex',\n      caption = \"Cross-tabulation of health by years of education\",\n      booktabs = T) %>%\nkable_styling(latex_options = c(\"hold_position\")) %>%\nadd_header_above(c(\"Years of Education\" = 1, \"Health condition by self-report\" = 5, \" \" = 1))\n```\n\n\n```{r}\nggplot(q3a)+\n  geom_boxplot(mapping = aes(x = educ_collapsed, y = health, group = educ_collapsed, fill = educ_collapsed))+\n  theme_light()+\n  labs(\n    x = \"Amount of Education\",\n    y = \"Health Condition\",\n    title = \"Figure 2: Boxplot of health by amount of education\",\n    caption = \"Based on data from the 2002 GSS.\"\n  )\n\n```\n\nAs the contingency table and the boxplot graph indicates, it seems that those with higher amounts of education tend to have better outcomes.\n\n## Univariate regression of health and education\n\nRunning a univariate linear regression of health against education, I find the same. There appears to be a postive relationship between education and health condition. Specifically, its $\\beta$ value of 0.0976 means that every year of education should improve a person's health condition by 0.0975. This linear model has an $R^2$ value of 0.03, which means that 3% of the variance in health outcome can be explained by variance of education around the regression line.\n\n```{r}\nq3a$black <- NA\nq3a$white <- NA\nq3a$black[q3a$race == 2] <- 1\nq3a$white[q3a$race == 2] <- 0\nq3a$white[q3a$race == 1] <- 1\nq3a$black[q3a$race == 1] <- 0\nq3a$black[q3a$race == 3] <- 0\nq3a$white[q3a$race == 3] <- 0\nq3a$age_cohort <- q3a$cohort - 1913\n```\n\n\n```{r}\nq3b <- drop_na(q3a, incom16, age_cohort, black, white)\n```\n\n```{r}\nlm1q3b <- lm(health~educ, q3b)\nlm2q3b <- lm(health~educ + incom16 , q3b)\nlm3q3b <- lm(health~educ + incom16 + age_cohort , q3b)\nlm4q3b <- lm(health~educ + incom16 + age_cohort + black + white , q3b)\n```\n\n\n```{r, results='asis'}\nstargazer(lm1q3b, header=FALSE)\n```\n\n\n```{r}\nggplot(q3b)+\n  geom_smooth(mapping = aes(x = educ, y = health), method = \"lm\", se = FALSE, show.legend =  TRUE)+\n  geom_jitter(mapping = aes(x = educ, y = health),height = 0.2, width = 0.2, alpha = 0.10)+\n  theme_light()+\n  labs(\n    x = \"Education (years)\",\n    y = \"Health Condition\",\n    title = \"Figure 3: Relationship between health and education\",\n    caption = \"Based on data from the 2002 GSS.\"\n  )\n\n```\n\n## Exploring spurious correlations: \n\n### Candidate 1: Childhood SES\n\nGiven a dependent variable as complex as health, we can imagine a multitude of confounders that may be causing a spurious association between health and education. As we learned in class, a confounder, or confounding variable, is a variable that is correlated with both the dependent variable and the independent variable. One likely candidate may be childhood SES. Childhood SES is related to education attainment, and likely correlates (if not causes) life habits that affect health outcomes. What's the best way to operationalize this, though? GSS has a question where they ask respondents about their SES at the age of 16, relatively to others. One problem with that question is that almost a quarter of respondents give N/A in response — in effect, I have to drop almost 500 observations from my analysis.\n\n### Candidate 2: Age\n\nIn the case of my data, another powerful confounder might be age. GSS data surveys people from a wide range of age cohorts. Individuals from different age cohorts might be predisposed towards different amounts of educational attainment; similar, there might be health events that affect their health conditions (a military draft; an epidemic perhaps; or even vaccination programs).\n\n### Candidate 3: Race\n\nFinally, I consider the effects of race as a confounder. Racialized access to education and healthcare option mean that race could easily be a source of spurious correlations. To simply matters, I operationalzie race as two dummy variables, black and white. Scoring zero on both would mean a respodent is an \"other\" on the GSS racial classification.\n\n\n```{r, results='asis'}\nstargazer(lm2q3b, lm3q3b, lm4q3b, \n          header=FALSE, \n          covariate.labels = c(\"Education\", \"Childhood SES\", \"Age\",\n                               \"Black\", \"White\"),\n          column.labels = c(\"Model 1\", \"Model 2\", 'Model 3'))\n```\n\n## Results\n\nObserving the linear models from the multi-regressions, I find that education appears to have a modest positive effect on health outcomes even when I control for the effects of age and childhood SES (SES at 16). Race does not appear to have a statistically signicant impact on health outcomes. All told, the $R^2$ values reported by the multiple regression were lower than I'd expected. The best performing model (model 2) only has a $R^2$ value of 0.044. That means only 4.4% of the variance in health conditions are explained by education. I was also surprised by the statistical insignifcance of racialized differences in health outcomes. \n\nThese departures from conventional results call for some introspection as to what might have gone awry. I suspect this might be a function of (a) the construct validity of my variable operationalizations and (b) missing observations. My meeasure of childhood SES might not be the best: perhaps I could have used parental education attainment as an alternative proxy. The GSS also might not be best suited for eliciting truthful responses of an individual's health condition: perhaps a data set that's more health-focused would have performed better. Missing data is another threat. A significant proportion, `r 455/2270*100`% (N of 495) of the GSS respondents did not provide a response to the childhood SES question. I naively dropped these non-responsences from all of my multiple regressions't. But perhaps I shouldn't just drop *this* many respondents willy nilly. This might not be the best way to deal with these NAs: for example, I could have used a K-nearest neighbors algorithm to match them up with the closest non-NA response, or assigned them a mean value (to be sure, I'm not sure how statistically defensible either of these treatments are). Who are these non-respondents?\n\n\n```{r}\nq3a$missingIncome <- \"Present\"\nq3a$missingIncome[is.na(q3a$incom16)] <- \"Absent\"\n\nmiss1 <-prop.table(table(q3a$missingIncome, q3a$race),2) %>% addmargins(1)*100\n\nmiss2 <-prop.table(table(q3a$missingIncome, q3a$educ_collapsed),2) %>% addmargins(1)*100\n\nmiss3 <-prop.table(table(q3a$missingIncome, q3a$health),2) %>% addmargins(1)*100\n\n```\n\n\n```{r}\nkable(miss1,\n      digits = 1, \n      row.names = TRUE,\n      col.names = c(\"White\", \"Black\", \"Others\"),\n      format = 'latex',\n      caption = \"Response/Non-response of Income16 by race\",\n      booktabs = T) %>%\nkable_styling(latex_options = c(\"hold_position\")) %>%\nadd_header_above(c(\" \" = 1, \"Race (%)\" = 3))\n\nkable(miss2,\n      digits = 1, \n      row.names = TRUE,\n      format = 'latex',\n      caption = \"Response/Non-response of Income16 by education\",\n      booktabs = T) %>%\nkable_styling(latex_options = c(\"hold_position\")) %>%\nadd_header_above(c(\" \" = 1, \"Education (%)\" = 6))\n\nkable(miss3,\n      digits = 1, \n      row.names = TRUE,\n      format = 'latex',\n      caption = \"Response/Non-response of Income16 by health\",\n      booktabs = T) %>%\nkable_styling(latex_options = c(\"hold_position\")) %>%\nadd_header_above(c(\" \" = 1, \"Health (%)\" = 5))\n```\n\nWe can see that non-respondents are not randomly distributed throughout the population. Non-respondents tend to have spent fewer years in education, and are more likely to have poor health. Thus, by dropping them, I am biasing my sample. This could account for the weakened $R^2$ value that I obtain.\n",
    "created" : 1539281128436.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4196032979",
    "id" : "7B91B03B",
    "lastKnownWriteTime" : 1523473013,
    "last_content_update" : 1523473013,
    "path" : "~/Documents/soc_stats_xi/hw2/hw2.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}